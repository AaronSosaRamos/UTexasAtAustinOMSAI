{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Background"
      ],
      "metadata": {
        "id": "6N6P1yxmzunN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPxkQcR4ztas"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Milestone 1: Perceptrons (1957)\n",
        "class Perceptron:\n",
        "    def __init__(self, num_inputs):\n",
        "        self.weights = np.random.rand(num_inputs)\n",
        "        self.bias = np.random.rand()\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        summation = np.dot(inputs, self.weights) + self.bias\n",
        "        return 1 if summation > 0 else 0\n",
        "\n",
        "# Milestone 2: Backpropagation (1970s-1980s)\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        self.hidden_weights = np.random.rand(num_inputs, num_hidden)\n",
        "        self.output_weights = np.random.rand(num_hidden, num_outputs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        hidden_layer = np.dot(inputs, self.hidden_weights)\n",
        "        hidden_layer_activation = self.sigmoid(hidden_layer)\n",
        "        output_layer = np.dot(hidden_layer_activation, self.output_weights)\n",
        "        return self.sigmoid(output_layer)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Milestone 3: Convolutional Neural Networks (CNNs) (1980s-1990s)\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Milestone 4: Deep Learning Frameworks (2000s-present)\n",
        "# TensorFlow Example\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Milestone 5: Transformers and Attention Mechanism (2017-present)\n",
        "# BERT (Bidirectional Encoder Representations from Transformers)\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
        "outputs = model(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Milestone 1: Perceptrons (1957)"
      ],
      "metadata": {
        "id": "PmkNzqcpz7Wl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceptrons were introduced by Frank Rosenblatt in 1957 as a simplified model of a biological neuron. They serve as the basic computational unit in early neural networks and paved the way for more complex architectures.\n",
        "\n",
        "A Perceptron takes multiple inputs, each weighted by a certain parameter, and produces a single binary output. Mathematically, a Perceptron computes a weighted sum of its inputs, applies a step function (or threshold activation function), and outputs a binary value based on whether the computed sum exceeds a certain threshold."
      ],
      "metadata": {
        "id": "yCxeZH4Hz-WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, num_inputs, learning_rate=0.1):\n",
        "        # Initialize weights randomly and set bias\n",
        "        self.weights = np.random.rand(num_inputs)\n",
        "        self.bias = np.random.rand()\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        # Compute the weighted sum of inputs and apply activation function (step function)\n",
        "        summation = np.dot(inputs, self.weights) + self.bias\n",
        "        output = 1 if summation > 0 else 0\n",
        "        return output\n",
        "\n",
        "    def train(self, training_inputs, labels, epochs):\n",
        "        for epoch in range(epochs):\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                # Update weights based on prediction error\n",
        "                error = label - prediction\n",
        "                self.weights += self.learning_rate * error * inputs\n",
        "                self.bias += self.learning_rate * error\n",
        "            print(f\"Epoch {epoch + 1}/{epochs} completed\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Training data (logical OR function)\n",
        "    training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    labels = np.array([0, 1, 1, 1])  # OR function labels\n",
        "\n",
        "    # Create and train Perceptron\n",
        "    perceptron = Perceptron(num_inputs=2, learning_rate=0.1)\n",
        "    perceptron.train(training_inputs, labels, epochs=10)\n",
        "\n",
        "    # Test the trained Perceptron\n",
        "    test_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    for inputs in test_inputs:\n",
        "        output = perceptron.predict(inputs)\n",
        "        print(f\"Input: {inputs} Predicted Output: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_8H1gLjz77t",
        "outputId": "662a4392-6ace-43b2-baa1-97f25cf60dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 completed\n",
            "Epoch 2/10 completed\n",
            "Epoch 3/10 completed\n",
            "Epoch 4/10 completed\n",
            "Epoch 5/10 completed\n",
            "Epoch 6/10 completed\n",
            "Epoch 7/10 completed\n",
            "Epoch 8/10 completed\n",
            "Epoch 9/10 completed\n",
            "Epoch 10/10 completed\n",
            "Input: [0 0] Predicted Output: 0\n",
            "Input: [0 1] Predicted Output: 1\n",
            "Input: [1 0] Predicted Output: 1\n",
            "Input: [1 1] Predicted Output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 2: Backpropagation (1970s-1980s)\n"
      ],
      "metadata": {
        "id": "8V9Rqmum0Z1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagation is a method for training neural networks by computing the gradient of the loss function with respect to the weights of the network. It enables the optimization of weights through gradient descent, allowing networks to learn from data and improve their performance over time.\n",
        "\n"
      ],
      "metadata": {
        "id": "-70DCkHv0mfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        # Initialize weights and biases for the hidden and output layers\n",
        "        self.hidden_weights = np.random.randn(num_inputs, num_hidden)\n",
        "        self.hidden_bias = np.random.randn(num_hidden)\n",
        "        self.output_weights = np.random.randn(num_hidden, num_outputs)\n",
        "        self.output_bias = np.random.randn(num_outputs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Forward pass through the network\n",
        "        hidden_layer_input = np.dot(inputs, self.hidden_weights) + self.hidden_bias\n",
        "        hidden_layer_output = self.sigmoid(hidden_layer_input)\n",
        "        output_layer_input = np.dot(hidden_layer_output, self.output_weights) + self.output_bias\n",
        "        predicted_output = self.sigmoid(output_layer_input)\n",
        "        return predicted_output\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # Sigmoid activation function\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        # Derivative of the sigmoid function\n",
        "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
        "\n",
        "    def train(self, inputs, targets, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            # Forward pass\n",
        "            hidden_layer_input = np.dot(inputs, self.hidden_weights) + self.hidden_bias\n",
        "            hidden_layer_output = self.sigmoid(hidden_layer_input)\n",
        "            output_layer_input = np.dot(hidden_layer_output, self.output_weights) + self.output_bias\n",
        "            predicted_output = self.sigmoid(output_layer_input)\n",
        "\n",
        "            # Backward pass (Backpropagation)\n",
        "            output_error = targets - predicted_output\n",
        "            output_delta = output_error * self.sigmoid_derivative(predicted_output)\n",
        "\n",
        "            hidden_error = np.dot(output_delta, self.output_weights.T)\n",
        "            hidden_delta = hidden_error * self.sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "            # Update weights and biases\n",
        "            self.output_weights += learning_rate * np.dot(hidden_layer_output.T, output_delta)\n",
        "            self.output_bias += learning_rate * np.sum(output_delta, axis=0)\n",
        "            self.hidden_weights += learning_rate * np.dot(inputs.T, hidden_delta)\n",
        "            self.hidden_bias += learning_rate * np.sum(hidden_delta, axis=0)\n",
        "\n",
        "            # Compute and print the mean squared error\n",
        "            mse = np.mean(np.square(output_error))\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define training data (XOR function)\n",
        "    inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    targets = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "    # Create and train Neural Network\n",
        "    nn = NeuralNetwork(num_inputs=2, num_hidden=4, num_outputs=1)\n",
        "    nn.train(inputs, targets, epochs=1000, learning_rate=0.1)\n",
        "\n",
        "    # Test the trained Neural Network\n",
        "    test_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    predictions = nn.forward(test_inputs)\n",
        "    print(\"Predictions after training:\")\n",
        "    for i in range(len(test_inputs)):\n",
        "        print(f\"Input: {test_inputs[i]}, Predicted Output: {predictions[i][0]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF3Rx0TC0aDG",
        "outputId": "e0170e26-8658-409f-faeb-b2d1db6e3043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Mean Squared Error: 0.2605\n",
            "Epoch 2/1000, Mean Squared Error: 0.2601\n",
            "Epoch 3/1000, Mean Squared Error: 0.2598\n",
            "Epoch 4/1000, Mean Squared Error: 0.2595\n",
            "Epoch 5/1000, Mean Squared Error: 0.2593\n",
            "Epoch 6/1000, Mean Squared Error: 0.2590\n",
            "Epoch 7/1000, Mean Squared Error: 0.2588\n",
            "Epoch 8/1000, Mean Squared Error: 0.2586\n",
            "Epoch 9/1000, Mean Squared Error: 0.2583\n",
            "Epoch 10/1000, Mean Squared Error: 0.2581\n",
            "Epoch 11/1000, Mean Squared Error: 0.2580\n",
            "Epoch 12/1000, Mean Squared Error: 0.2578\n",
            "Epoch 13/1000, Mean Squared Error: 0.2576\n",
            "Epoch 14/1000, Mean Squared Error: 0.2574\n",
            "Epoch 15/1000, Mean Squared Error: 0.2573\n",
            "Epoch 16/1000, Mean Squared Error: 0.2571\n",
            "Epoch 17/1000, Mean Squared Error: 0.2570\n",
            "Epoch 18/1000, Mean Squared Error: 0.2569\n",
            "Epoch 19/1000, Mean Squared Error: 0.2567\n",
            "Epoch 20/1000, Mean Squared Error: 0.2566\n",
            "Epoch 21/1000, Mean Squared Error: 0.2565\n",
            "Epoch 22/1000, Mean Squared Error: 0.2564\n",
            "Epoch 23/1000, Mean Squared Error: 0.2563\n",
            "Epoch 24/1000, Mean Squared Error: 0.2562\n",
            "Epoch 25/1000, Mean Squared Error: 0.2561\n",
            "Epoch 26/1000, Mean Squared Error: 0.2560\n",
            "Epoch 27/1000, Mean Squared Error: 0.2559\n",
            "Epoch 28/1000, Mean Squared Error: 0.2558\n",
            "Epoch 29/1000, Mean Squared Error: 0.2558\n",
            "Epoch 30/1000, Mean Squared Error: 0.2557\n",
            "Epoch 31/1000, Mean Squared Error: 0.2556\n",
            "Epoch 32/1000, Mean Squared Error: 0.2555\n",
            "Epoch 33/1000, Mean Squared Error: 0.2555\n",
            "Epoch 34/1000, Mean Squared Error: 0.2554\n",
            "Epoch 35/1000, Mean Squared Error: 0.2553\n",
            "Epoch 36/1000, Mean Squared Error: 0.2553\n",
            "Epoch 37/1000, Mean Squared Error: 0.2552\n",
            "Epoch 38/1000, Mean Squared Error: 0.2552\n",
            "Epoch 39/1000, Mean Squared Error: 0.2551\n",
            "Epoch 40/1000, Mean Squared Error: 0.2551\n",
            "Epoch 41/1000, Mean Squared Error: 0.2550\n",
            "Epoch 42/1000, Mean Squared Error: 0.2550\n",
            "Epoch 43/1000, Mean Squared Error: 0.2549\n",
            "Epoch 44/1000, Mean Squared Error: 0.2549\n",
            "Epoch 45/1000, Mean Squared Error: 0.2548\n",
            "Epoch 46/1000, Mean Squared Error: 0.2548\n",
            "Epoch 47/1000, Mean Squared Error: 0.2547\n",
            "Epoch 48/1000, Mean Squared Error: 0.2547\n",
            "Epoch 49/1000, Mean Squared Error: 0.2547\n",
            "Epoch 50/1000, Mean Squared Error: 0.2546\n",
            "Epoch 51/1000, Mean Squared Error: 0.2546\n",
            "Epoch 52/1000, Mean Squared Error: 0.2545\n",
            "Epoch 53/1000, Mean Squared Error: 0.2545\n",
            "Epoch 54/1000, Mean Squared Error: 0.2545\n",
            "Epoch 55/1000, Mean Squared Error: 0.2544\n",
            "Epoch 56/1000, Mean Squared Error: 0.2544\n",
            "Epoch 57/1000, Mean Squared Error: 0.2544\n",
            "Epoch 58/1000, Mean Squared Error: 0.2543\n",
            "Epoch 59/1000, Mean Squared Error: 0.2543\n",
            "Epoch 60/1000, Mean Squared Error: 0.2543\n",
            "Epoch 61/1000, Mean Squared Error: 0.2542\n",
            "Epoch 62/1000, Mean Squared Error: 0.2542\n",
            "Epoch 63/1000, Mean Squared Error: 0.2542\n",
            "Epoch 64/1000, Mean Squared Error: 0.2541\n",
            "Epoch 65/1000, Mean Squared Error: 0.2541\n",
            "Epoch 66/1000, Mean Squared Error: 0.2541\n",
            "Epoch 67/1000, Mean Squared Error: 0.2540\n",
            "Epoch 68/1000, Mean Squared Error: 0.2540\n",
            "Epoch 69/1000, Mean Squared Error: 0.2540\n",
            "Epoch 70/1000, Mean Squared Error: 0.2540\n",
            "Epoch 71/1000, Mean Squared Error: 0.2539\n",
            "Epoch 72/1000, Mean Squared Error: 0.2539\n",
            "Epoch 73/1000, Mean Squared Error: 0.2539\n",
            "Epoch 74/1000, Mean Squared Error: 0.2539\n",
            "Epoch 75/1000, Mean Squared Error: 0.2538\n",
            "Epoch 76/1000, Mean Squared Error: 0.2538\n",
            "Epoch 77/1000, Mean Squared Error: 0.2538\n",
            "Epoch 78/1000, Mean Squared Error: 0.2537\n",
            "Epoch 79/1000, Mean Squared Error: 0.2537\n",
            "Epoch 80/1000, Mean Squared Error: 0.2537\n",
            "Epoch 81/1000, Mean Squared Error: 0.2537\n",
            "Epoch 82/1000, Mean Squared Error: 0.2536\n",
            "Epoch 83/1000, Mean Squared Error: 0.2536\n",
            "Epoch 84/1000, Mean Squared Error: 0.2536\n",
            "Epoch 85/1000, Mean Squared Error: 0.2536\n",
            "Epoch 86/1000, Mean Squared Error: 0.2536\n",
            "Epoch 87/1000, Mean Squared Error: 0.2535\n",
            "Epoch 88/1000, Mean Squared Error: 0.2535\n",
            "Epoch 89/1000, Mean Squared Error: 0.2535\n",
            "Epoch 90/1000, Mean Squared Error: 0.2535\n",
            "Epoch 91/1000, Mean Squared Error: 0.2534\n",
            "Epoch 92/1000, Mean Squared Error: 0.2534\n",
            "Epoch 93/1000, Mean Squared Error: 0.2534\n",
            "Epoch 94/1000, Mean Squared Error: 0.2534\n",
            "Epoch 95/1000, Mean Squared Error: 0.2533\n",
            "Epoch 96/1000, Mean Squared Error: 0.2533\n",
            "Epoch 97/1000, Mean Squared Error: 0.2533\n",
            "Epoch 98/1000, Mean Squared Error: 0.2533\n",
            "Epoch 99/1000, Mean Squared Error: 0.2533\n",
            "Epoch 100/1000, Mean Squared Error: 0.2532\n",
            "Epoch 101/1000, Mean Squared Error: 0.2532\n",
            "Epoch 102/1000, Mean Squared Error: 0.2532\n",
            "Epoch 103/1000, Mean Squared Error: 0.2532\n",
            "Epoch 104/1000, Mean Squared Error: 0.2531\n",
            "Epoch 105/1000, Mean Squared Error: 0.2531\n",
            "Epoch 106/1000, Mean Squared Error: 0.2531\n",
            "Epoch 107/1000, Mean Squared Error: 0.2531\n",
            "Epoch 108/1000, Mean Squared Error: 0.2531\n",
            "Epoch 109/1000, Mean Squared Error: 0.2530\n",
            "Epoch 110/1000, Mean Squared Error: 0.2530\n",
            "Epoch 111/1000, Mean Squared Error: 0.2530\n",
            "Epoch 112/1000, Mean Squared Error: 0.2530\n",
            "Epoch 113/1000, Mean Squared Error: 0.2529\n",
            "Epoch 114/1000, Mean Squared Error: 0.2529\n",
            "Epoch 115/1000, Mean Squared Error: 0.2529\n",
            "Epoch 116/1000, Mean Squared Error: 0.2529\n",
            "Epoch 117/1000, Mean Squared Error: 0.2529\n",
            "Epoch 118/1000, Mean Squared Error: 0.2528\n",
            "Epoch 119/1000, Mean Squared Error: 0.2528\n",
            "Epoch 120/1000, Mean Squared Error: 0.2528\n",
            "Epoch 121/1000, Mean Squared Error: 0.2528\n",
            "Epoch 122/1000, Mean Squared Error: 0.2528\n",
            "Epoch 123/1000, Mean Squared Error: 0.2527\n",
            "Epoch 124/1000, Mean Squared Error: 0.2527\n",
            "Epoch 125/1000, Mean Squared Error: 0.2527\n",
            "Epoch 126/1000, Mean Squared Error: 0.2527\n",
            "Epoch 127/1000, Mean Squared Error: 0.2527\n",
            "Epoch 128/1000, Mean Squared Error: 0.2526\n",
            "Epoch 129/1000, Mean Squared Error: 0.2526\n",
            "Epoch 130/1000, Mean Squared Error: 0.2526\n",
            "Epoch 131/1000, Mean Squared Error: 0.2526\n",
            "Epoch 132/1000, Mean Squared Error: 0.2526\n",
            "Epoch 133/1000, Mean Squared Error: 0.2525\n",
            "Epoch 134/1000, Mean Squared Error: 0.2525\n",
            "Epoch 135/1000, Mean Squared Error: 0.2525\n",
            "Epoch 136/1000, Mean Squared Error: 0.2525\n",
            "Epoch 137/1000, Mean Squared Error: 0.2525\n",
            "Epoch 138/1000, Mean Squared Error: 0.2524\n",
            "Epoch 139/1000, Mean Squared Error: 0.2524\n",
            "Epoch 140/1000, Mean Squared Error: 0.2524\n",
            "Epoch 141/1000, Mean Squared Error: 0.2524\n",
            "Epoch 142/1000, Mean Squared Error: 0.2524\n",
            "Epoch 143/1000, Mean Squared Error: 0.2523\n",
            "Epoch 144/1000, Mean Squared Error: 0.2523\n",
            "Epoch 145/1000, Mean Squared Error: 0.2523\n",
            "Epoch 146/1000, Mean Squared Error: 0.2523\n",
            "Epoch 147/1000, Mean Squared Error: 0.2523\n",
            "Epoch 148/1000, Mean Squared Error: 0.2523\n",
            "Epoch 149/1000, Mean Squared Error: 0.2522\n",
            "Epoch 150/1000, Mean Squared Error: 0.2522\n",
            "Epoch 151/1000, Mean Squared Error: 0.2522\n",
            "Epoch 152/1000, Mean Squared Error: 0.2522\n",
            "Epoch 153/1000, Mean Squared Error: 0.2522\n",
            "Epoch 154/1000, Mean Squared Error: 0.2521\n",
            "Epoch 155/1000, Mean Squared Error: 0.2521\n",
            "Epoch 156/1000, Mean Squared Error: 0.2521\n",
            "Epoch 157/1000, Mean Squared Error: 0.2521\n",
            "Epoch 158/1000, Mean Squared Error: 0.2521\n",
            "Epoch 159/1000, Mean Squared Error: 0.2521\n",
            "Epoch 160/1000, Mean Squared Error: 0.2520\n",
            "Epoch 161/1000, Mean Squared Error: 0.2520\n",
            "Epoch 162/1000, Mean Squared Error: 0.2520\n",
            "Epoch 163/1000, Mean Squared Error: 0.2520\n",
            "Epoch 164/1000, Mean Squared Error: 0.2520\n",
            "Epoch 165/1000, Mean Squared Error: 0.2519\n",
            "Epoch 166/1000, Mean Squared Error: 0.2519\n",
            "Epoch 167/1000, Mean Squared Error: 0.2519\n",
            "Epoch 168/1000, Mean Squared Error: 0.2519\n",
            "Epoch 169/1000, Mean Squared Error: 0.2519\n",
            "Epoch 170/1000, Mean Squared Error: 0.2519\n",
            "Epoch 171/1000, Mean Squared Error: 0.2518\n",
            "Epoch 172/1000, Mean Squared Error: 0.2518\n",
            "Epoch 173/1000, Mean Squared Error: 0.2518\n",
            "Epoch 174/1000, Mean Squared Error: 0.2518\n",
            "Epoch 175/1000, Mean Squared Error: 0.2518\n",
            "Epoch 176/1000, Mean Squared Error: 0.2517\n",
            "Epoch 177/1000, Mean Squared Error: 0.2517\n",
            "Epoch 178/1000, Mean Squared Error: 0.2517\n",
            "Epoch 179/1000, Mean Squared Error: 0.2517\n",
            "Epoch 180/1000, Mean Squared Error: 0.2517\n",
            "Epoch 181/1000, Mean Squared Error: 0.2517\n",
            "Epoch 182/1000, Mean Squared Error: 0.2516\n",
            "Epoch 183/1000, Mean Squared Error: 0.2516\n",
            "Epoch 184/1000, Mean Squared Error: 0.2516\n",
            "Epoch 185/1000, Mean Squared Error: 0.2516\n",
            "Epoch 186/1000, Mean Squared Error: 0.2516\n",
            "Epoch 187/1000, Mean Squared Error: 0.2516\n",
            "Epoch 188/1000, Mean Squared Error: 0.2515\n",
            "Epoch 189/1000, Mean Squared Error: 0.2515\n",
            "Epoch 190/1000, Mean Squared Error: 0.2515\n",
            "Epoch 191/1000, Mean Squared Error: 0.2515\n",
            "Epoch 192/1000, Mean Squared Error: 0.2515\n",
            "Epoch 193/1000, Mean Squared Error: 0.2515\n",
            "Epoch 194/1000, Mean Squared Error: 0.2514\n",
            "Epoch 195/1000, Mean Squared Error: 0.2514\n",
            "Epoch 196/1000, Mean Squared Error: 0.2514\n",
            "Epoch 197/1000, Mean Squared Error: 0.2514\n",
            "Epoch 198/1000, Mean Squared Error: 0.2514\n",
            "Epoch 199/1000, Mean Squared Error: 0.2513\n",
            "Epoch 200/1000, Mean Squared Error: 0.2513\n",
            "Epoch 201/1000, Mean Squared Error: 0.2513\n",
            "Epoch 202/1000, Mean Squared Error: 0.2513\n",
            "Epoch 203/1000, Mean Squared Error: 0.2513\n",
            "Epoch 204/1000, Mean Squared Error: 0.2513\n",
            "Epoch 205/1000, Mean Squared Error: 0.2512\n",
            "Epoch 206/1000, Mean Squared Error: 0.2512\n",
            "Epoch 207/1000, Mean Squared Error: 0.2512\n",
            "Epoch 208/1000, Mean Squared Error: 0.2512\n",
            "Epoch 209/1000, Mean Squared Error: 0.2512\n",
            "Epoch 210/1000, Mean Squared Error: 0.2512\n",
            "Epoch 211/1000, Mean Squared Error: 0.2511\n",
            "Epoch 212/1000, Mean Squared Error: 0.2511\n",
            "Epoch 213/1000, Mean Squared Error: 0.2511\n",
            "Epoch 214/1000, Mean Squared Error: 0.2511\n",
            "Epoch 215/1000, Mean Squared Error: 0.2511\n",
            "Epoch 216/1000, Mean Squared Error: 0.2511\n",
            "Epoch 217/1000, Mean Squared Error: 0.2511\n",
            "Epoch 218/1000, Mean Squared Error: 0.2510\n",
            "Epoch 219/1000, Mean Squared Error: 0.2510\n",
            "Epoch 220/1000, Mean Squared Error: 0.2510\n",
            "Epoch 221/1000, Mean Squared Error: 0.2510\n",
            "Epoch 222/1000, Mean Squared Error: 0.2510\n",
            "Epoch 223/1000, Mean Squared Error: 0.2510\n",
            "Epoch 224/1000, Mean Squared Error: 0.2509\n",
            "Epoch 225/1000, Mean Squared Error: 0.2509\n",
            "Epoch 226/1000, Mean Squared Error: 0.2509\n",
            "Epoch 227/1000, Mean Squared Error: 0.2509\n",
            "Epoch 228/1000, Mean Squared Error: 0.2509\n",
            "Epoch 229/1000, Mean Squared Error: 0.2509\n",
            "Epoch 230/1000, Mean Squared Error: 0.2508\n",
            "Epoch 231/1000, Mean Squared Error: 0.2508\n",
            "Epoch 232/1000, Mean Squared Error: 0.2508\n",
            "Epoch 233/1000, Mean Squared Error: 0.2508\n",
            "Epoch 234/1000, Mean Squared Error: 0.2508\n",
            "Epoch 235/1000, Mean Squared Error: 0.2508\n",
            "Epoch 236/1000, Mean Squared Error: 0.2508\n",
            "Epoch 237/1000, Mean Squared Error: 0.2507\n",
            "Epoch 238/1000, Mean Squared Error: 0.2507\n",
            "Epoch 239/1000, Mean Squared Error: 0.2507\n",
            "Epoch 240/1000, Mean Squared Error: 0.2507\n",
            "Epoch 241/1000, Mean Squared Error: 0.2507\n",
            "Epoch 242/1000, Mean Squared Error: 0.2507\n",
            "Epoch 243/1000, Mean Squared Error: 0.2506\n",
            "Epoch 244/1000, Mean Squared Error: 0.2506\n",
            "Epoch 245/1000, Mean Squared Error: 0.2506\n",
            "Epoch 246/1000, Mean Squared Error: 0.2506\n",
            "Epoch 247/1000, Mean Squared Error: 0.2506\n",
            "Epoch 248/1000, Mean Squared Error: 0.2506\n",
            "Epoch 249/1000, Mean Squared Error: 0.2505\n",
            "Epoch 250/1000, Mean Squared Error: 0.2505\n",
            "Epoch 251/1000, Mean Squared Error: 0.2505\n",
            "Epoch 252/1000, Mean Squared Error: 0.2505\n",
            "Epoch 253/1000, Mean Squared Error: 0.2505\n",
            "Epoch 254/1000, Mean Squared Error: 0.2505\n",
            "Epoch 255/1000, Mean Squared Error: 0.2505\n",
            "Epoch 256/1000, Mean Squared Error: 0.2504\n",
            "Epoch 257/1000, Mean Squared Error: 0.2504\n",
            "Epoch 258/1000, Mean Squared Error: 0.2504\n",
            "Epoch 259/1000, Mean Squared Error: 0.2504\n",
            "Epoch 260/1000, Mean Squared Error: 0.2504\n",
            "Epoch 261/1000, Mean Squared Error: 0.2504\n",
            "Epoch 262/1000, Mean Squared Error: 0.2504\n",
            "Epoch 263/1000, Mean Squared Error: 0.2503\n",
            "Epoch 264/1000, Mean Squared Error: 0.2503\n",
            "Epoch 265/1000, Mean Squared Error: 0.2503\n",
            "Epoch 266/1000, Mean Squared Error: 0.2503\n",
            "Epoch 267/1000, Mean Squared Error: 0.2503\n",
            "Epoch 268/1000, Mean Squared Error: 0.2503\n",
            "Epoch 269/1000, Mean Squared Error: 0.2503\n",
            "Epoch 270/1000, Mean Squared Error: 0.2502\n",
            "Epoch 271/1000, Mean Squared Error: 0.2502\n",
            "Epoch 272/1000, Mean Squared Error: 0.2502\n",
            "Epoch 273/1000, Mean Squared Error: 0.2502\n",
            "Epoch 274/1000, Mean Squared Error: 0.2502\n",
            "Epoch 275/1000, Mean Squared Error: 0.2502\n",
            "Epoch 276/1000, Mean Squared Error: 0.2501\n",
            "Epoch 277/1000, Mean Squared Error: 0.2501\n",
            "Epoch 278/1000, Mean Squared Error: 0.2501\n",
            "Epoch 279/1000, Mean Squared Error: 0.2501\n",
            "Epoch 280/1000, Mean Squared Error: 0.2501\n",
            "Epoch 281/1000, Mean Squared Error: 0.2501\n",
            "Epoch 282/1000, Mean Squared Error: 0.2501\n",
            "Epoch 283/1000, Mean Squared Error: 0.2500\n",
            "Epoch 284/1000, Mean Squared Error: 0.2500\n",
            "Epoch 285/1000, Mean Squared Error: 0.2500\n",
            "Epoch 286/1000, Mean Squared Error: 0.2500\n",
            "Epoch 287/1000, Mean Squared Error: 0.2500\n",
            "Epoch 288/1000, Mean Squared Error: 0.2500\n",
            "Epoch 289/1000, Mean Squared Error: 0.2500\n",
            "Epoch 290/1000, Mean Squared Error: 0.2499\n",
            "Epoch 291/1000, Mean Squared Error: 0.2499\n",
            "Epoch 292/1000, Mean Squared Error: 0.2499\n",
            "Epoch 293/1000, Mean Squared Error: 0.2499\n",
            "Epoch 294/1000, Mean Squared Error: 0.2499\n",
            "Epoch 295/1000, Mean Squared Error: 0.2499\n",
            "Epoch 296/1000, Mean Squared Error: 0.2499\n",
            "Epoch 297/1000, Mean Squared Error: 0.2498\n",
            "Epoch 298/1000, Mean Squared Error: 0.2498\n",
            "Epoch 299/1000, Mean Squared Error: 0.2498\n",
            "Epoch 300/1000, Mean Squared Error: 0.2498\n",
            "Epoch 301/1000, Mean Squared Error: 0.2498\n",
            "Epoch 302/1000, Mean Squared Error: 0.2498\n",
            "Epoch 303/1000, Mean Squared Error: 0.2498\n",
            "Epoch 304/1000, Mean Squared Error: 0.2498\n",
            "Epoch 305/1000, Mean Squared Error: 0.2497\n",
            "Epoch 306/1000, Mean Squared Error: 0.2497\n",
            "Epoch 307/1000, Mean Squared Error: 0.2497\n",
            "Epoch 308/1000, Mean Squared Error: 0.2497\n",
            "Epoch 309/1000, Mean Squared Error: 0.2497\n",
            "Epoch 310/1000, Mean Squared Error: 0.2497\n",
            "Epoch 311/1000, Mean Squared Error: 0.2497\n",
            "Epoch 312/1000, Mean Squared Error: 0.2496\n",
            "Epoch 313/1000, Mean Squared Error: 0.2496\n",
            "Epoch 314/1000, Mean Squared Error: 0.2496\n",
            "Epoch 315/1000, Mean Squared Error: 0.2496\n",
            "Epoch 316/1000, Mean Squared Error: 0.2496\n",
            "Epoch 317/1000, Mean Squared Error: 0.2496\n",
            "Epoch 318/1000, Mean Squared Error: 0.2496\n",
            "Epoch 319/1000, Mean Squared Error: 0.2495\n",
            "Epoch 320/1000, Mean Squared Error: 0.2495\n",
            "Epoch 321/1000, Mean Squared Error: 0.2495\n",
            "Epoch 322/1000, Mean Squared Error: 0.2495\n",
            "Epoch 323/1000, Mean Squared Error: 0.2495\n",
            "Epoch 324/1000, Mean Squared Error: 0.2495\n",
            "Epoch 325/1000, Mean Squared Error: 0.2495\n",
            "Epoch 326/1000, Mean Squared Error: 0.2495\n",
            "Epoch 327/1000, Mean Squared Error: 0.2494\n",
            "Epoch 328/1000, Mean Squared Error: 0.2494\n",
            "Epoch 329/1000, Mean Squared Error: 0.2494\n",
            "Epoch 330/1000, Mean Squared Error: 0.2494\n",
            "Epoch 331/1000, Mean Squared Error: 0.2494\n",
            "Epoch 332/1000, Mean Squared Error: 0.2494\n",
            "Epoch 333/1000, Mean Squared Error: 0.2494\n",
            "Epoch 334/1000, Mean Squared Error: 0.2493\n",
            "Epoch 335/1000, Mean Squared Error: 0.2493\n",
            "Epoch 336/1000, Mean Squared Error: 0.2493\n",
            "Epoch 337/1000, Mean Squared Error: 0.2493\n",
            "Epoch 338/1000, Mean Squared Error: 0.2493\n",
            "Epoch 339/1000, Mean Squared Error: 0.2493\n",
            "Epoch 340/1000, Mean Squared Error: 0.2493\n",
            "Epoch 341/1000, Mean Squared Error: 0.2493\n",
            "Epoch 342/1000, Mean Squared Error: 0.2492\n",
            "Epoch 343/1000, Mean Squared Error: 0.2492\n",
            "Epoch 344/1000, Mean Squared Error: 0.2492\n",
            "Epoch 345/1000, Mean Squared Error: 0.2492\n",
            "Epoch 346/1000, Mean Squared Error: 0.2492\n",
            "Epoch 347/1000, Mean Squared Error: 0.2492\n",
            "Epoch 348/1000, Mean Squared Error: 0.2492\n",
            "Epoch 349/1000, Mean Squared Error: 0.2491\n",
            "Epoch 350/1000, Mean Squared Error: 0.2491\n",
            "Epoch 351/1000, Mean Squared Error: 0.2491\n",
            "Epoch 352/1000, Mean Squared Error: 0.2491\n",
            "Epoch 353/1000, Mean Squared Error: 0.2491\n",
            "Epoch 354/1000, Mean Squared Error: 0.2491\n",
            "Epoch 355/1000, Mean Squared Error: 0.2491\n",
            "Epoch 356/1000, Mean Squared Error: 0.2491\n",
            "Epoch 357/1000, Mean Squared Error: 0.2490\n",
            "Epoch 358/1000, Mean Squared Error: 0.2490\n",
            "Epoch 359/1000, Mean Squared Error: 0.2490\n",
            "Epoch 360/1000, Mean Squared Error: 0.2490\n",
            "Epoch 361/1000, Mean Squared Error: 0.2490\n",
            "Epoch 362/1000, Mean Squared Error: 0.2490\n",
            "Epoch 363/1000, Mean Squared Error: 0.2490\n",
            "Epoch 364/1000, Mean Squared Error: 0.2490\n",
            "Epoch 365/1000, Mean Squared Error: 0.2489\n",
            "Epoch 366/1000, Mean Squared Error: 0.2489\n",
            "Epoch 367/1000, Mean Squared Error: 0.2489\n",
            "Epoch 368/1000, Mean Squared Error: 0.2489\n",
            "Epoch 369/1000, Mean Squared Error: 0.2489\n",
            "Epoch 370/1000, Mean Squared Error: 0.2489\n",
            "Epoch 371/1000, Mean Squared Error: 0.2489\n",
            "Epoch 372/1000, Mean Squared Error: 0.2489\n",
            "Epoch 373/1000, Mean Squared Error: 0.2488\n",
            "Epoch 374/1000, Mean Squared Error: 0.2488\n",
            "Epoch 375/1000, Mean Squared Error: 0.2488\n",
            "Epoch 376/1000, Mean Squared Error: 0.2488\n",
            "Epoch 377/1000, Mean Squared Error: 0.2488\n",
            "Epoch 378/1000, Mean Squared Error: 0.2488\n",
            "Epoch 379/1000, Mean Squared Error: 0.2488\n",
            "Epoch 380/1000, Mean Squared Error: 0.2488\n",
            "Epoch 381/1000, Mean Squared Error: 0.2487\n",
            "Epoch 382/1000, Mean Squared Error: 0.2487\n",
            "Epoch 383/1000, Mean Squared Error: 0.2487\n",
            "Epoch 384/1000, Mean Squared Error: 0.2487\n",
            "Epoch 385/1000, Mean Squared Error: 0.2487\n",
            "Epoch 386/1000, Mean Squared Error: 0.2487\n",
            "Epoch 387/1000, Mean Squared Error: 0.2487\n",
            "Epoch 388/1000, Mean Squared Error: 0.2487\n",
            "Epoch 389/1000, Mean Squared Error: 0.2486\n",
            "Epoch 390/1000, Mean Squared Error: 0.2486\n",
            "Epoch 391/1000, Mean Squared Error: 0.2486\n",
            "Epoch 392/1000, Mean Squared Error: 0.2486\n",
            "Epoch 393/1000, Mean Squared Error: 0.2486\n",
            "Epoch 394/1000, Mean Squared Error: 0.2486\n",
            "Epoch 395/1000, Mean Squared Error: 0.2486\n",
            "Epoch 396/1000, Mean Squared Error: 0.2486\n",
            "Epoch 397/1000, Mean Squared Error: 0.2485\n",
            "Epoch 398/1000, Mean Squared Error: 0.2485\n",
            "Epoch 399/1000, Mean Squared Error: 0.2485\n",
            "Epoch 400/1000, Mean Squared Error: 0.2485\n",
            "Epoch 401/1000, Mean Squared Error: 0.2485\n",
            "Epoch 402/1000, Mean Squared Error: 0.2485\n",
            "Epoch 403/1000, Mean Squared Error: 0.2485\n",
            "Epoch 404/1000, Mean Squared Error: 0.2485\n",
            "Epoch 405/1000, Mean Squared Error: 0.2485\n",
            "Epoch 406/1000, Mean Squared Error: 0.2484\n",
            "Epoch 407/1000, Mean Squared Error: 0.2484\n",
            "Epoch 408/1000, Mean Squared Error: 0.2484\n",
            "Epoch 409/1000, Mean Squared Error: 0.2484\n",
            "Epoch 410/1000, Mean Squared Error: 0.2484\n",
            "Epoch 411/1000, Mean Squared Error: 0.2484\n",
            "Epoch 412/1000, Mean Squared Error: 0.2484\n",
            "Epoch 413/1000, Mean Squared Error: 0.2484\n",
            "Epoch 414/1000, Mean Squared Error: 0.2483\n",
            "Epoch 415/1000, Mean Squared Error: 0.2483\n",
            "Epoch 416/1000, Mean Squared Error: 0.2483\n",
            "Epoch 417/1000, Mean Squared Error: 0.2483\n",
            "Epoch 418/1000, Mean Squared Error: 0.2483\n",
            "Epoch 419/1000, Mean Squared Error: 0.2483\n",
            "Epoch 420/1000, Mean Squared Error: 0.2483\n",
            "Epoch 421/1000, Mean Squared Error: 0.2483\n",
            "Epoch 422/1000, Mean Squared Error: 0.2483\n",
            "Epoch 423/1000, Mean Squared Error: 0.2482\n",
            "Epoch 424/1000, Mean Squared Error: 0.2482\n",
            "Epoch 425/1000, Mean Squared Error: 0.2482\n",
            "Epoch 426/1000, Mean Squared Error: 0.2482\n",
            "Epoch 427/1000, Mean Squared Error: 0.2482\n",
            "Epoch 428/1000, Mean Squared Error: 0.2482\n",
            "Epoch 429/1000, Mean Squared Error: 0.2482\n",
            "Epoch 430/1000, Mean Squared Error: 0.2482\n",
            "Epoch 431/1000, Mean Squared Error: 0.2481\n",
            "Epoch 432/1000, Mean Squared Error: 0.2481\n",
            "Epoch 433/1000, Mean Squared Error: 0.2481\n",
            "Epoch 434/1000, Mean Squared Error: 0.2481\n",
            "Epoch 435/1000, Mean Squared Error: 0.2481\n",
            "Epoch 436/1000, Mean Squared Error: 0.2481\n",
            "Epoch 437/1000, Mean Squared Error: 0.2481\n",
            "Epoch 438/1000, Mean Squared Error: 0.2481\n",
            "Epoch 439/1000, Mean Squared Error: 0.2481\n",
            "Epoch 440/1000, Mean Squared Error: 0.2480\n",
            "Epoch 441/1000, Mean Squared Error: 0.2480\n",
            "Epoch 442/1000, Mean Squared Error: 0.2480\n",
            "Epoch 443/1000, Mean Squared Error: 0.2480\n",
            "Epoch 444/1000, Mean Squared Error: 0.2480\n",
            "Epoch 445/1000, Mean Squared Error: 0.2480\n",
            "Epoch 446/1000, Mean Squared Error: 0.2480\n",
            "Epoch 447/1000, Mean Squared Error: 0.2480\n",
            "Epoch 448/1000, Mean Squared Error: 0.2480\n",
            "Epoch 449/1000, Mean Squared Error: 0.2479\n",
            "Epoch 450/1000, Mean Squared Error: 0.2479\n",
            "Epoch 451/1000, Mean Squared Error: 0.2479\n",
            "Epoch 452/1000, Mean Squared Error: 0.2479\n",
            "Epoch 453/1000, Mean Squared Error: 0.2479\n",
            "Epoch 454/1000, Mean Squared Error: 0.2479\n",
            "Epoch 455/1000, Mean Squared Error: 0.2479\n",
            "Epoch 456/1000, Mean Squared Error: 0.2479\n",
            "Epoch 457/1000, Mean Squared Error: 0.2478\n",
            "Epoch 458/1000, Mean Squared Error: 0.2478\n",
            "Epoch 459/1000, Mean Squared Error: 0.2478\n",
            "Epoch 460/1000, Mean Squared Error: 0.2478\n",
            "Epoch 461/1000, Mean Squared Error: 0.2478\n",
            "Epoch 462/1000, Mean Squared Error: 0.2478\n",
            "Epoch 463/1000, Mean Squared Error: 0.2478\n",
            "Epoch 464/1000, Mean Squared Error: 0.2478\n",
            "Epoch 465/1000, Mean Squared Error: 0.2478\n",
            "Epoch 466/1000, Mean Squared Error: 0.2477\n",
            "Epoch 467/1000, Mean Squared Error: 0.2477\n",
            "Epoch 468/1000, Mean Squared Error: 0.2477\n",
            "Epoch 469/1000, Mean Squared Error: 0.2477\n",
            "Epoch 470/1000, Mean Squared Error: 0.2477\n",
            "Epoch 471/1000, Mean Squared Error: 0.2477\n",
            "Epoch 472/1000, Mean Squared Error: 0.2477\n",
            "Epoch 473/1000, Mean Squared Error: 0.2477\n",
            "Epoch 474/1000, Mean Squared Error: 0.2477\n",
            "Epoch 475/1000, Mean Squared Error: 0.2476\n",
            "Epoch 476/1000, Mean Squared Error: 0.2476\n",
            "Epoch 477/1000, Mean Squared Error: 0.2476\n",
            "Epoch 478/1000, Mean Squared Error: 0.2476\n",
            "Epoch 479/1000, Mean Squared Error: 0.2476\n",
            "Epoch 480/1000, Mean Squared Error: 0.2476\n",
            "Epoch 481/1000, Mean Squared Error: 0.2476\n",
            "Epoch 482/1000, Mean Squared Error: 0.2476\n",
            "Epoch 483/1000, Mean Squared Error: 0.2476\n",
            "Epoch 484/1000, Mean Squared Error: 0.2476\n",
            "Epoch 485/1000, Mean Squared Error: 0.2475\n",
            "Epoch 486/1000, Mean Squared Error: 0.2475\n",
            "Epoch 487/1000, Mean Squared Error: 0.2475\n",
            "Epoch 488/1000, Mean Squared Error: 0.2475\n",
            "Epoch 489/1000, Mean Squared Error: 0.2475\n",
            "Epoch 490/1000, Mean Squared Error: 0.2475\n",
            "Epoch 491/1000, Mean Squared Error: 0.2475\n",
            "Epoch 492/1000, Mean Squared Error: 0.2475\n",
            "Epoch 493/1000, Mean Squared Error: 0.2475\n",
            "Epoch 494/1000, Mean Squared Error: 0.2474\n",
            "Epoch 495/1000, Mean Squared Error: 0.2474\n",
            "Epoch 496/1000, Mean Squared Error: 0.2474\n",
            "Epoch 497/1000, Mean Squared Error: 0.2474\n",
            "Epoch 498/1000, Mean Squared Error: 0.2474\n",
            "Epoch 499/1000, Mean Squared Error: 0.2474\n",
            "Epoch 500/1000, Mean Squared Error: 0.2474\n",
            "Epoch 501/1000, Mean Squared Error: 0.2474\n",
            "Epoch 502/1000, Mean Squared Error: 0.2474\n",
            "Epoch 503/1000, Mean Squared Error: 0.2473\n",
            "Epoch 504/1000, Mean Squared Error: 0.2473\n",
            "Epoch 505/1000, Mean Squared Error: 0.2473\n",
            "Epoch 506/1000, Mean Squared Error: 0.2473\n",
            "Epoch 507/1000, Mean Squared Error: 0.2473\n",
            "Epoch 508/1000, Mean Squared Error: 0.2473\n",
            "Epoch 509/1000, Mean Squared Error: 0.2473\n",
            "Epoch 510/1000, Mean Squared Error: 0.2473\n",
            "Epoch 511/1000, Mean Squared Error: 0.2473\n",
            "Epoch 512/1000, Mean Squared Error: 0.2472\n",
            "Epoch 513/1000, Mean Squared Error: 0.2472\n",
            "Epoch 514/1000, Mean Squared Error: 0.2472\n",
            "Epoch 515/1000, Mean Squared Error: 0.2472\n",
            "Epoch 516/1000, Mean Squared Error: 0.2472\n",
            "Epoch 517/1000, Mean Squared Error: 0.2472\n",
            "Epoch 518/1000, Mean Squared Error: 0.2472\n",
            "Epoch 519/1000, Mean Squared Error: 0.2472\n",
            "Epoch 520/1000, Mean Squared Error: 0.2472\n",
            "Epoch 521/1000, Mean Squared Error: 0.2472\n",
            "Epoch 522/1000, Mean Squared Error: 0.2471\n",
            "Epoch 523/1000, Mean Squared Error: 0.2471\n",
            "Epoch 524/1000, Mean Squared Error: 0.2471\n",
            "Epoch 525/1000, Mean Squared Error: 0.2471\n",
            "Epoch 526/1000, Mean Squared Error: 0.2471\n",
            "Epoch 527/1000, Mean Squared Error: 0.2471\n",
            "Epoch 528/1000, Mean Squared Error: 0.2471\n",
            "Epoch 529/1000, Mean Squared Error: 0.2471\n",
            "Epoch 530/1000, Mean Squared Error: 0.2471\n",
            "Epoch 531/1000, Mean Squared Error: 0.2470\n",
            "Epoch 532/1000, Mean Squared Error: 0.2470\n",
            "Epoch 533/1000, Mean Squared Error: 0.2470\n",
            "Epoch 534/1000, Mean Squared Error: 0.2470\n",
            "Epoch 535/1000, Mean Squared Error: 0.2470\n",
            "Epoch 536/1000, Mean Squared Error: 0.2470\n",
            "Epoch 537/1000, Mean Squared Error: 0.2470\n",
            "Epoch 538/1000, Mean Squared Error: 0.2470\n",
            "Epoch 539/1000, Mean Squared Error: 0.2470\n",
            "Epoch 540/1000, Mean Squared Error: 0.2470\n",
            "Epoch 541/1000, Mean Squared Error: 0.2469\n",
            "Epoch 542/1000, Mean Squared Error: 0.2469\n",
            "Epoch 543/1000, Mean Squared Error: 0.2469\n",
            "Epoch 544/1000, Mean Squared Error: 0.2469\n",
            "Epoch 545/1000, Mean Squared Error: 0.2469\n",
            "Epoch 546/1000, Mean Squared Error: 0.2469\n",
            "Epoch 547/1000, Mean Squared Error: 0.2469\n",
            "Epoch 548/1000, Mean Squared Error: 0.2469\n",
            "Epoch 549/1000, Mean Squared Error: 0.2469\n",
            "Epoch 550/1000, Mean Squared Error: 0.2469\n",
            "Epoch 551/1000, Mean Squared Error: 0.2468\n",
            "Epoch 552/1000, Mean Squared Error: 0.2468\n",
            "Epoch 553/1000, Mean Squared Error: 0.2468\n",
            "Epoch 554/1000, Mean Squared Error: 0.2468\n",
            "Epoch 555/1000, Mean Squared Error: 0.2468\n",
            "Epoch 556/1000, Mean Squared Error: 0.2468\n",
            "Epoch 557/1000, Mean Squared Error: 0.2468\n",
            "Epoch 558/1000, Mean Squared Error: 0.2468\n",
            "Epoch 559/1000, Mean Squared Error: 0.2468\n",
            "Epoch 560/1000, Mean Squared Error: 0.2468\n",
            "Epoch 561/1000, Mean Squared Error: 0.2467\n",
            "Epoch 562/1000, Mean Squared Error: 0.2467\n",
            "Epoch 563/1000, Mean Squared Error: 0.2467\n",
            "Epoch 564/1000, Mean Squared Error: 0.2467\n",
            "Epoch 565/1000, Mean Squared Error: 0.2467\n",
            "Epoch 566/1000, Mean Squared Error: 0.2467\n",
            "Epoch 567/1000, Mean Squared Error: 0.2467\n",
            "Epoch 568/1000, Mean Squared Error: 0.2467\n",
            "Epoch 569/1000, Mean Squared Error: 0.2467\n",
            "Epoch 570/1000, Mean Squared Error: 0.2466\n",
            "Epoch 571/1000, Mean Squared Error: 0.2466\n",
            "Epoch 572/1000, Mean Squared Error: 0.2466\n",
            "Epoch 573/1000, Mean Squared Error: 0.2466\n",
            "Epoch 574/1000, Mean Squared Error: 0.2466\n",
            "Epoch 575/1000, Mean Squared Error: 0.2466\n",
            "Epoch 576/1000, Mean Squared Error: 0.2466\n",
            "Epoch 577/1000, Mean Squared Error: 0.2466\n",
            "Epoch 578/1000, Mean Squared Error: 0.2466\n",
            "Epoch 579/1000, Mean Squared Error: 0.2466\n",
            "Epoch 580/1000, Mean Squared Error: 0.2465\n",
            "Epoch 581/1000, Mean Squared Error: 0.2465\n",
            "Epoch 582/1000, Mean Squared Error: 0.2465\n",
            "Epoch 583/1000, Mean Squared Error: 0.2465\n",
            "Epoch 584/1000, Mean Squared Error: 0.2465\n",
            "Epoch 585/1000, Mean Squared Error: 0.2465\n",
            "Epoch 586/1000, Mean Squared Error: 0.2465\n",
            "Epoch 587/1000, Mean Squared Error: 0.2465\n",
            "Epoch 588/1000, Mean Squared Error: 0.2465\n",
            "Epoch 589/1000, Mean Squared Error: 0.2465\n",
            "Epoch 590/1000, Mean Squared Error: 0.2465\n",
            "Epoch 591/1000, Mean Squared Error: 0.2464\n",
            "Epoch 592/1000, Mean Squared Error: 0.2464\n",
            "Epoch 593/1000, Mean Squared Error: 0.2464\n",
            "Epoch 594/1000, Mean Squared Error: 0.2464\n",
            "Epoch 595/1000, Mean Squared Error: 0.2464\n",
            "Epoch 596/1000, Mean Squared Error: 0.2464\n",
            "Epoch 597/1000, Mean Squared Error: 0.2464\n",
            "Epoch 598/1000, Mean Squared Error: 0.2464\n",
            "Epoch 599/1000, Mean Squared Error: 0.2464\n",
            "Epoch 600/1000, Mean Squared Error: 0.2464\n",
            "Epoch 601/1000, Mean Squared Error: 0.2463\n",
            "Epoch 602/1000, Mean Squared Error: 0.2463\n",
            "Epoch 603/1000, Mean Squared Error: 0.2463\n",
            "Epoch 604/1000, Mean Squared Error: 0.2463\n",
            "Epoch 605/1000, Mean Squared Error: 0.2463\n",
            "Epoch 606/1000, Mean Squared Error: 0.2463\n",
            "Epoch 607/1000, Mean Squared Error: 0.2463\n",
            "Epoch 608/1000, Mean Squared Error: 0.2463\n",
            "Epoch 609/1000, Mean Squared Error: 0.2463\n",
            "Epoch 610/1000, Mean Squared Error: 0.2463\n",
            "Epoch 611/1000, Mean Squared Error: 0.2462\n",
            "Epoch 612/1000, Mean Squared Error: 0.2462\n",
            "Epoch 613/1000, Mean Squared Error: 0.2462\n",
            "Epoch 614/1000, Mean Squared Error: 0.2462\n",
            "Epoch 615/1000, Mean Squared Error: 0.2462\n",
            "Epoch 616/1000, Mean Squared Error: 0.2462\n",
            "Epoch 617/1000, Mean Squared Error: 0.2462\n",
            "Epoch 618/1000, Mean Squared Error: 0.2462\n",
            "Epoch 619/1000, Mean Squared Error: 0.2462\n",
            "Epoch 620/1000, Mean Squared Error: 0.2462\n",
            "Epoch 621/1000, Mean Squared Error: 0.2461\n",
            "Epoch 622/1000, Mean Squared Error: 0.2461\n",
            "Epoch 623/1000, Mean Squared Error: 0.2461\n",
            "Epoch 624/1000, Mean Squared Error: 0.2461\n",
            "Epoch 625/1000, Mean Squared Error: 0.2461\n",
            "Epoch 626/1000, Mean Squared Error: 0.2461\n",
            "Epoch 627/1000, Mean Squared Error: 0.2461\n",
            "Epoch 628/1000, Mean Squared Error: 0.2461\n",
            "Epoch 629/1000, Mean Squared Error: 0.2461\n",
            "Epoch 630/1000, Mean Squared Error: 0.2461\n",
            "Epoch 631/1000, Mean Squared Error: 0.2461\n",
            "Epoch 632/1000, Mean Squared Error: 0.2460\n",
            "Epoch 633/1000, Mean Squared Error: 0.2460\n",
            "Epoch 634/1000, Mean Squared Error: 0.2460\n",
            "Epoch 635/1000, Mean Squared Error: 0.2460\n",
            "Epoch 636/1000, Mean Squared Error: 0.2460\n",
            "Epoch 637/1000, Mean Squared Error: 0.2460\n",
            "Epoch 638/1000, Mean Squared Error: 0.2460\n",
            "Epoch 639/1000, Mean Squared Error: 0.2460\n",
            "Epoch 640/1000, Mean Squared Error: 0.2460\n",
            "Epoch 641/1000, Mean Squared Error: 0.2460\n",
            "Epoch 642/1000, Mean Squared Error: 0.2459\n",
            "Epoch 643/1000, Mean Squared Error: 0.2459\n",
            "Epoch 644/1000, Mean Squared Error: 0.2459\n",
            "Epoch 645/1000, Mean Squared Error: 0.2459\n",
            "Epoch 646/1000, Mean Squared Error: 0.2459\n",
            "Epoch 647/1000, Mean Squared Error: 0.2459\n",
            "Epoch 648/1000, Mean Squared Error: 0.2459\n",
            "Epoch 649/1000, Mean Squared Error: 0.2459\n",
            "Epoch 650/1000, Mean Squared Error: 0.2459\n",
            "Epoch 651/1000, Mean Squared Error: 0.2459\n",
            "Epoch 652/1000, Mean Squared Error: 0.2459\n",
            "Epoch 653/1000, Mean Squared Error: 0.2458\n",
            "Epoch 654/1000, Mean Squared Error: 0.2458\n",
            "Epoch 655/1000, Mean Squared Error: 0.2458\n",
            "Epoch 656/1000, Mean Squared Error: 0.2458\n",
            "Epoch 657/1000, Mean Squared Error: 0.2458\n",
            "Epoch 658/1000, Mean Squared Error: 0.2458\n",
            "Epoch 659/1000, Mean Squared Error: 0.2458\n",
            "Epoch 660/1000, Mean Squared Error: 0.2458\n",
            "Epoch 661/1000, Mean Squared Error: 0.2458\n",
            "Epoch 662/1000, Mean Squared Error: 0.2458\n",
            "Epoch 663/1000, Mean Squared Error: 0.2457\n",
            "Epoch 664/1000, Mean Squared Error: 0.2457\n",
            "Epoch 665/1000, Mean Squared Error: 0.2457\n",
            "Epoch 666/1000, Mean Squared Error: 0.2457\n",
            "Epoch 667/1000, Mean Squared Error: 0.2457\n",
            "Epoch 668/1000, Mean Squared Error: 0.2457\n",
            "Epoch 669/1000, Mean Squared Error: 0.2457\n",
            "Epoch 670/1000, Mean Squared Error: 0.2457\n",
            "Epoch 671/1000, Mean Squared Error: 0.2457\n",
            "Epoch 672/1000, Mean Squared Error: 0.2457\n",
            "Epoch 673/1000, Mean Squared Error: 0.2457\n",
            "Epoch 674/1000, Mean Squared Error: 0.2456\n",
            "Epoch 675/1000, Mean Squared Error: 0.2456\n",
            "Epoch 676/1000, Mean Squared Error: 0.2456\n",
            "Epoch 677/1000, Mean Squared Error: 0.2456\n",
            "Epoch 678/1000, Mean Squared Error: 0.2456\n",
            "Epoch 679/1000, Mean Squared Error: 0.2456\n",
            "Epoch 680/1000, Mean Squared Error: 0.2456\n",
            "Epoch 681/1000, Mean Squared Error: 0.2456\n",
            "Epoch 682/1000, Mean Squared Error: 0.2456\n",
            "Epoch 683/1000, Mean Squared Error: 0.2456\n",
            "Epoch 684/1000, Mean Squared Error: 0.2456\n",
            "Epoch 685/1000, Mean Squared Error: 0.2455\n",
            "Epoch 686/1000, Mean Squared Error: 0.2455\n",
            "Epoch 687/1000, Mean Squared Error: 0.2455\n",
            "Epoch 688/1000, Mean Squared Error: 0.2455\n",
            "Epoch 689/1000, Mean Squared Error: 0.2455\n",
            "Epoch 690/1000, Mean Squared Error: 0.2455\n",
            "Epoch 691/1000, Mean Squared Error: 0.2455\n",
            "Epoch 692/1000, Mean Squared Error: 0.2455\n",
            "Epoch 693/1000, Mean Squared Error: 0.2455\n",
            "Epoch 694/1000, Mean Squared Error: 0.2455\n",
            "Epoch 695/1000, Mean Squared Error: 0.2455\n",
            "Epoch 696/1000, Mean Squared Error: 0.2454\n",
            "Epoch 697/1000, Mean Squared Error: 0.2454\n",
            "Epoch 698/1000, Mean Squared Error: 0.2454\n",
            "Epoch 699/1000, Mean Squared Error: 0.2454\n",
            "Epoch 700/1000, Mean Squared Error: 0.2454\n",
            "Epoch 701/1000, Mean Squared Error: 0.2454\n",
            "Epoch 702/1000, Mean Squared Error: 0.2454\n",
            "Epoch 703/1000, Mean Squared Error: 0.2454\n",
            "Epoch 704/1000, Mean Squared Error: 0.2454\n",
            "Epoch 705/1000, Mean Squared Error: 0.2454\n",
            "Epoch 706/1000, Mean Squared Error: 0.2454\n",
            "Epoch 707/1000, Mean Squared Error: 0.2453\n",
            "Epoch 708/1000, Mean Squared Error: 0.2453\n",
            "Epoch 709/1000, Mean Squared Error: 0.2453\n",
            "Epoch 710/1000, Mean Squared Error: 0.2453\n",
            "Epoch 711/1000, Mean Squared Error: 0.2453\n",
            "Epoch 712/1000, Mean Squared Error: 0.2453\n",
            "Epoch 713/1000, Mean Squared Error: 0.2453\n",
            "Epoch 714/1000, Mean Squared Error: 0.2453\n",
            "Epoch 715/1000, Mean Squared Error: 0.2453\n",
            "Epoch 716/1000, Mean Squared Error: 0.2453\n",
            "Epoch 717/1000, Mean Squared Error: 0.2453\n",
            "Epoch 718/1000, Mean Squared Error: 0.2452\n",
            "Epoch 719/1000, Mean Squared Error: 0.2452\n",
            "Epoch 720/1000, Mean Squared Error: 0.2452\n",
            "Epoch 721/1000, Mean Squared Error: 0.2452\n",
            "Epoch 722/1000, Mean Squared Error: 0.2452\n",
            "Epoch 723/1000, Mean Squared Error: 0.2452\n",
            "Epoch 724/1000, Mean Squared Error: 0.2452\n",
            "Epoch 725/1000, Mean Squared Error: 0.2452\n",
            "Epoch 726/1000, Mean Squared Error: 0.2452\n",
            "Epoch 727/1000, Mean Squared Error: 0.2452\n",
            "Epoch 728/1000, Mean Squared Error: 0.2452\n",
            "Epoch 729/1000, Mean Squared Error: 0.2451\n",
            "Epoch 730/1000, Mean Squared Error: 0.2451\n",
            "Epoch 731/1000, Mean Squared Error: 0.2451\n",
            "Epoch 732/1000, Mean Squared Error: 0.2451\n",
            "Epoch 733/1000, Mean Squared Error: 0.2451\n",
            "Epoch 734/1000, Mean Squared Error: 0.2451\n",
            "Epoch 735/1000, Mean Squared Error: 0.2451\n",
            "Epoch 736/1000, Mean Squared Error: 0.2451\n",
            "Epoch 737/1000, Mean Squared Error: 0.2451\n",
            "Epoch 738/1000, Mean Squared Error: 0.2451\n",
            "Epoch 739/1000, Mean Squared Error: 0.2451\n",
            "Epoch 740/1000, Mean Squared Error: 0.2450\n",
            "Epoch 741/1000, Mean Squared Error: 0.2450\n",
            "Epoch 742/1000, Mean Squared Error: 0.2450\n",
            "Epoch 743/1000, Mean Squared Error: 0.2450\n",
            "Epoch 744/1000, Mean Squared Error: 0.2450\n",
            "Epoch 745/1000, Mean Squared Error: 0.2450\n",
            "Epoch 746/1000, Mean Squared Error: 0.2450\n",
            "Epoch 747/1000, Mean Squared Error: 0.2450\n",
            "Epoch 748/1000, Mean Squared Error: 0.2450\n",
            "Epoch 749/1000, Mean Squared Error: 0.2450\n",
            "Epoch 750/1000, Mean Squared Error: 0.2450\n",
            "Epoch 751/1000, Mean Squared Error: 0.2449\n",
            "Epoch 752/1000, Mean Squared Error: 0.2449\n",
            "Epoch 753/1000, Mean Squared Error: 0.2449\n",
            "Epoch 754/1000, Mean Squared Error: 0.2449\n",
            "Epoch 755/1000, Mean Squared Error: 0.2449\n",
            "Epoch 756/1000, Mean Squared Error: 0.2449\n",
            "Epoch 757/1000, Mean Squared Error: 0.2449\n",
            "Epoch 758/1000, Mean Squared Error: 0.2449\n",
            "Epoch 759/1000, Mean Squared Error: 0.2449\n",
            "Epoch 760/1000, Mean Squared Error: 0.2449\n",
            "Epoch 761/1000, Mean Squared Error: 0.2449\n",
            "Epoch 762/1000, Mean Squared Error: 0.2448\n",
            "Epoch 763/1000, Mean Squared Error: 0.2448\n",
            "Epoch 764/1000, Mean Squared Error: 0.2448\n",
            "Epoch 765/1000, Mean Squared Error: 0.2448\n",
            "Epoch 766/1000, Mean Squared Error: 0.2448\n",
            "Epoch 767/1000, Mean Squared Error: 0.2448\n",
            "Epoch 768/1000, Mean Squared Error: 0.2448\n",
            "Epoch 769/1000, Mean Squared Error: 0.2448\n",
            "Epoch 770/1000, Mean Squared Error: 0.2448\n",
            "Epoch 771/1000, Mean Squared Error: 0.2448\n",
            "Epoch 772/1000, Mean Squared Error: 0.2448\n",
            "Epoch 773/1000, Mean Squared Error: 0.2448\n",
            "Epoch 774/1000, Mean Squared Error: 0.2447\n",
            "Epoch 775/1000, Mean Squared Error: 0.2447\n",
            "Epoch 776/1000, Mean Squared Error: 0.2447\n",
            "Epoch 777/1000, Mean Squared Error: 0.2447\n",
            "Epoch 778/1000, Mean Squared Error: 0.2447\n",
            "Epoch 779/1000, Mean Squared Error: 0.2447\n",
            "Epoch 780/1000, Mean Squared Error: 0.2447\n",
            "Epoch 781/1000, Mean Squared Error: 0.2447\n",
            "Epoch 782/1000, Mean Squared Error: 0.2447\n",
            "Epoch 783/1000, Mean Squared Error: 0.2447\n",
            "Epoch 784/1000, Mean Squared Error: 0.2447\n",
            "Epoch 785/1000, Mean Squared Error: 0.2446\n",
            "Epoch 786/1000, Mean Squared Error: 0.2446\n",
            "Epoch 787/1000, Mean Squared Error: 0.2446\n",
            "Epoch 788/1000, Mean Squared Error: 0.2446\n",
            "Epoch 789/1000, Mean Squared Error: 0.2446\n",
            "Epoch 790/1000, Mean Squared Error: 0.2446\n",
            "Epoch 791/1000, Mean Squared Error: 0.2446\n",
            "Epoch 792/1000, Mean Squared Error: 0.2446\n",
            "Epoch 793/1000, Mean Squared Error: 0.2446\n",
            "Epoch 794/1000, Mean Squared Error: 0.2446\n",
            "Epoch 795/1000, Mean Squared Error: 0.2446\n",
            "Epoch 796/1000, Mean Squared Error: 0.2446\n",
            "Epoch 797/1000, Mean Squared Error: 0.2445\n",
            "Epoch 798/1000, Mean Squared Error: 0.2445\n",
            "Epoch 799/1000, Mean Squared Error: 0.2445\n",
            "Epoch 800/1000, Mean Squared Error: 0.2445\n",
            "Epoch 801/1000, Mean Squared Error: 0.2445\n",
            "Epoch 802/1000, Mean Squared Error: 0.2445\n",
            "Epoch 803/1000, Mean Squared Error: 0.2445\n",
            "Epoch 804/1000, Mean Squared Error: 0.2445\n",
            "Epoch 805/1000, Mean Squared Error: 0.2445\n",
            "Epoch 806/1000, Mean Squared Error: 0.2445\n",
            "Epoch 807/1000, Mean Squared Error: 0.2445\n",
            "Epoch 808/1000, Mean Squared Error: 0.2445\n",
            "Epoch 809/1000, Mean Squared Error: 0.2444\n",
            "Epoch 810/1000, Mean Squared Error: 0.2444\n",
            "Epoch 811/1000, Mean Squared Error: 0.2444\n",
            "Epoch 812/1000, Mean Squared Error: 0.2444\n",
            "Epoch 813/1000, Mean Squared Error: 0.2444\n",
            "Epoch 814/1000, Mean Squared Error: 0.2444\n",
            "Epoch 815/1000, Mean Squared Error: 0.2444\n",
            "Epoch 816/1000, Mean Squared Error: 0.2444\n",
            "Epoch 817/1000, Mean Squared Error: 0.2444\n",
            "Epoch 818/1000, Mean Squared Error: 0.2444\n",
            "Epoch 819/1000, Mean Squared Error: 0.2444\n",
            "Epoch 820/1000, Mean Squared Error: 0.2443\n",
            "Epoch 821/1000, Mean Squared Error: 0.2443\n",
            "Epoch 822/1000, Mean Squared Error: 0.2443\n",
            "Epoch 823/1000, Mean Squared Error: 0.2443\n",
            "Epoch 824/1000, Mean Squared Error: 0.2443\n",
            "Epoch 825/1000, Mean Squared Error: 0.2443\n",
            "Epoch 826/1000, Mean Squared Error: 0.2443\n",
            "Epoch 827/1000, Mean Squared Error: 0.2443\n",
            "Epoch 828/1000, Mean Squared Error: 0.2443\n",
            "Epoch 829/1000, Mean Squared Error: 0.2443\n",
            "Epoch 830/1000, Mean Squared Error: 0.2443\n",
            "Epoch 831/1000, Mean Squared Error: 0.2443\n",
            "Epoch 832/1000, Mean Squared Error: 0.2442\n",
            "Epoch 833/1000, Mean Squared Error: 0.2442\n",
            "Epoch 834/1000, Mean Squared Error: 0.2442\n",
            "Epoch 835/1000, Mean Squared Error: 0.2442\n",
            "Epoch 836/1000, Mean Squared Error: 0.2442\n",
            "Epoch 837/1000, Mean Squared Error: 0.2442\n",
            "Epoch 838/1000, Mean Squared Error: 0.2442\n",
            "Epoch 839/1000, Mean Squared Error: 0.2442\n",
            "Epoch 840/1000, Mean Squared Error: 0.2442\n",
            "Epoch 841/1000, Mean Squared Error: 0.2442\n",
            "Epoch 842/1000, Mean Squared Error: 0.2442\n",
            "Epoch 843/1000, Mean Squared Error: 0.2442\n",
            "Epoch 844/1000, Mean Squared Error: 0.2441\n",
            "Epoch 845/1000, Mean Squared Error: 0.2441\n",
            "Epoch 846/1000, Mean Squared Error: 0.2441\n",
            "Epoch 847/1000, Mean Squared Error: 0.2441\n",
            "Epoch 848/1000, Mean Squared Error: 0.2441\n",
            "Epoch 849/1000, Mean Squared Error: 0.2441\n",
            "Epoch 850/1000, Mean Squared Error: 0.2441\n",
            "Epoch 851/1000, Mean Squared Error: 0.2441\n",
            "Epoch 852/1000, Mean Squared Error: 0.2441\n",
            "Epoch 853/1000, Mean Squared Error: 0.2441\n",
            "Epoch 854/1000, Mean Squared Error: 0.2441\n",
            "Epoch 855/1000, Mean Squared Error: 0.2441\n",
            "Epoch 856/1000, Mean Squared Error: 0.2440\n",
            "Epoch 857/1000, Mean Squared Error: 0.2440\n",
            "Epoch 858/1000, Mean Squared Error: 0.2440\n",
            "Epoch 859/1000, Mean Squared Error: 0.2440\n",
            "Epoch 860/1000, Mean Squared Error: 0.2440\n",
            "Epoch 861/1000, Mean Squared Error: 0.2440\n",
            "Epoch 862/1000, Mean Squared Error: 0.2440\n",
            "Epoch 863/1000, Mean Squared Error: 0.2440\n",
            "Epoch 864/1000, Mean Squared Error: 0.2440\n",
            "Epoch 865/1000, Mean Squared Error: 0.2440\n",
            "Epoch 866/1000, Mean Squared Error: 0.2440\n",
            "Epoch 867/1000, Mean Squared Error: 0.2440\n",
            "Epoch 868/1000, Mean Squared Error: 0.2439\n",
            "Epoch 869/1000, Mean Squared Error: 0.2439\n",
            "Epoch 870/1000, Mean Squared Error: 0.2439\n",
            "Epoch 871/1000, Mean Squared Error: 0.2439\n",
            "Epoch 872/1000, Mean Squared Error: 0.2439\n",
            "Epoch 873/1000, Mean Squared Error: 0.2439\n",
            "Epoch 874/1000, Mean Squared Error: 0.2439\n",
            "Epoch 875/1000, Mean Squared Error: 0.2439\n",
            "Epoch 876/1000, Mean Squared Error: 0.2439\n",
            "Epoch 877/1000, Mean Squared Error: 0.2439\n",
            "Epoch 878/1000, Mean Squared Error: 0.2439\n",
            "Epoch 879/1000, Mean Squared Error: 0.2439\n",
            "Epoch 880/1000, Mean Squared Error: 0.2438\n",
            "Epoch 881/1000, Mean Squared Error: 0.2438\n",
            "Epoch 882/1000, Mean Squared Error: 0.2438\n",
            "Epoch 883/1000, Mean Squared Error: 0.2438\n",
            "Epoch 884/1000, Mean Squared Error: 0.2438\n",
            "Epoch 885/1000, Mean Squared Error: 0.2438\n",
            "Epoch 886/1000, Mean Squared Error: 0.2438\n",
            "Epoch 887/1000, Mean Squared Error: 0.2438\n",
            "Epoch 888/1000, Mean Squared Error: 0.2438\n",
            "Epoch 889/1000, Mean Squared Error: 0.2438\n",
            "Epoch 890/1000, Mean Squared Error: 0.2438\n",
            "Epoch 891/1000, Mean Squared Error: 0.2438\n",
            "Epoch 892/1000, Mean Squared Error: 0.2437\n",
            "Epoch 893/1000, Mean Squared Error: 0.2437\n",
            "Epoch 894/1000, Mean Squared Error: 0.2437\n",
            "Epoch 895/1000, Mean Squared Error: 0.2437\n",
            "Epoch 896/1000, Mean Squared Error: 0.2437\n",
            "Epoch 897/1000, Mean Squared Error: 0.2437\n",
            "Epoch 898/1000, Mean Squared Error: 0.2437\n",
            "Epoch 899/1000, Mean Squared Error: 0.2437\n",
            "Epoch 900/1000, Mean Squared Error: 0.2437\n",
            "Epoch 901/1000, Mean Squared Error: 0.2437\n",
            "Epoch 902/1000, Mean Squared Error: 0.2437\n",
            "Epoch 903/1000, Mean Squared Error: 0.2437\n",
            "Epoch 904/1000, Mean Squared Error: 0.2436\n",
            "Epoch 905/1000, Mean Squared Error: 0.2436\n",
            "Epoch 906/1000, Mean Squared Error: 0.2436\n",
            "Epoch 907/1000, Mean Squared Error: 0.2436\n",
            "Epoch 908/1000, Mean Squared Error: 0.2436\n",
            "Epoch 909/1000, Mean Squared Error: 0.2436\n",
            "Epoch 910/1000, Mean Squared Error: 0.2436\n",
            "Epoch 911/1000, Mean Squared Error: 0.2436\n",
            "Epoch 912/1000, Mean Squared Error: 0.2436\n",
            "Epoch 913/1000, Mean Squared Error: 0.2436\n",
            "Epoch 914/1000, Mean Squared Error: 0.2436\n",
            "Epoch 915/1000, Mean Squared Error: 0.2436\n",
            "Epoch 916/1000, Mean Squared Error: 0.2436\n",
            "Epoch 917/1000, Mean Squared Error: 0.2435\n",
            "Epoch 918/1000, Mean Squared Error: 0.2435\n",
            "Epoch 919/1000, Mean Squared Error: 0.2435\n",
            "Epoch 920/1000, Mean Squared Error: 0.2435\n",
            "Epoch 921/1000, Mean Squared Error: 0.2435\n",
            "Epoch 922/1000, Mean Squared Error: 0.2435\n",
            "Epoch 923/1000, Mean Squared Error: 0.2435\n",
            "Epoch 924/1000, Mean Squared Error: 0.2435\n",
            "Epoch 925/1000, Mean Squared Error: 0.2435\n",
            "Epoch 926/1000, Mean Squared Error: 0.2435\n",
            "Epoch 927/1000, Mean Squared Error: 0.2435\n",
            "Epoch 928/1000, Mean Squared Error: 0.2435\n",
            "Epoch 929/1000, Mean Squared Error: 0.2434\n",
            "Epoch 930/1000, Mean Squared Error: 0.2434\n",
            "Epoch 931/1000, Mean Squared Error: 0.2434\n",
            "Epoch 932/1000, Mean Squared Error: 0.2434\n",
            "Epoch 933/1000, Mean Squared Error: 0.2434\n",
            "Epoch 934/1000, Mean Squared Error: 0.2434\n",
            "Epoch 935/1000, Mean Squared Error: 0.2434\n",
            "Epoch 936/1000, Mean Squared Error: 0.2434\n",
            "Epoch 937/1000, Mean Squared Error: 0.2434\n",
            "Epoch 938/1000, Mean Squared Error: 0.2434\n",
            "Epoch 939/1000, Mean Squared Error: 0.2434\n",
            "Epoch 940/1000, Mean Squared Error: 0.2434\n",
            "Epoch 941/1000, Mean Squared Error: 0.2434\n",
            "Epoch 942/1000, Mean Squared Error: 0.2433\n",
            "Epoch 943/1000, Mean Squared Error: 0.2433\n",
            "Epoch 944/1000, Mean Squared Error: 0.2433\n",
            "Epoch 945/1000, Mean Squared Error: 0.2433\n",
            "Epoch 946/1000, Mean Squared Error: 0.2433\n",
            "Epoch 947/1000, Mean Squared Error: 0.2433\n",
            "Epoch 948/1000, Mean Squared Error: 0.2433\n",
            "Epoch 949/1000, Mean Squared Error: 0.2433\n",
            "Epoch 950/1000, Mean Squared Error: 0.2433\n",
            "Epoch 951/1000, Mean Squared Error: 0.2433\n",
            "Epoch 952/1000, Mean Squared Error: 0.2433\n",
            "Epoch 953/1000, Mean Squared Error: 0.2433\n",
            "Epoch 954/1000, Mean Squared Error: 0.2432\n",
            "Epoch 955/1000, Mean Squared Error: 0.2432\n",
            "Epoch 956/1000, Mean Squared Error: 0.2432\n",
            "Epoch 957/1000, Mean Squared Error: 0.2432\n",
            "Epoch 958/1000, Mean Squared Error: 0.2432\n",
            "Epoch 959/1000, Mean Squared Error: 0.2432\n",
            "Epoch 960/1000, Mean Squared Error: 0.2432\n",
            "Epoch 961/1000, Mean Squared Error: 0.2432\n",
            "Epoch 962/1000, Mean Squared Error: 0.2432\n",
            "Epoch 963/1000, Mean Squared Error: 0.2432\n",
            "Epoch 964/1000, Mean Squared Error: 0.2432\n",
            "Epoch 965/1000, Mean Squared Error: 0.2432\n",
            "Epoch 966/1000, Mean Squared Error: 0.2432\n",
            "Epoch 967/1000, Mean Squared Error: 0.2431\n",
            "Epoch 968/1000, Mean Squared Error: 0.2431\n",
            "Epoch 969/1000, Mean Squared Error: 0.2431\n",
            "Epoch 970/1000, Mean Squared Error: 0.2431\n",
            "Epoch 971/1000, Mean Squared Error: 0.2431\n",
            "Epoch 972/1000, Mean Squared Error: 0.2431\n",
            "Epoch 973/1000, Mean Squared Error: 0.2431\n",
            "Epoch 974/1000, Mean Squared Error: 0.2431\n",
            "Epoch 975/1000, Mean Squared Error: 0.2431\n",
            "Epoch 976/1000, Mean Squared Error: 0.2431\n",
            "Epoch 977/1000, Mean Squared Error: 0.2431\n",
            "Epoch 978/1000, Mean Squared Error: 0.2431\n",
            "Epoch 979/1000, Mean Squared Error: 0.2430\n",
            "Epoch 980/1000, Mean Squared Error: 0.2430\n",
            "Epoch 981/1000, Mean Squared Error: 0.2430\n",
            "Epoch 982/1000, Mean Squared Error: 0.2430\n",
            "Epoch 983/1000, Mean Squared Error: 0.2430\n",
            "Epoch 984/1000, Mean Squared Error: 0.2430\n",
            "Epoch 985/1000, Mean Squared Error: 0.2430\n",
            "Epoch 986/1000, Mean Squared Error: 0.2430\n",
            "Epoch 987/1000, Mean Squared Error: 0.2430\n",
            "Epoch 988/1000, Mean Squared Error: 0.2430\n",
            "Epoch 989/1000, Mean Squared Error: 0.2430\n",
            "Epoch 990/1000, Mean Squared Error: 0.2430\n",
            "Epoch 991/1000, Mean Squared Error: 0.2430\n",
            "Epoch 992/1000, Mean Squared Error: 0.2429\n",
            "Epoch 993/1000, Mean Squared Error: 0.2429\n",
            "Epoch 994/1000, Mean Squared Error: 0.2429\n",
            "Epoch 995/1000, Mean Squared Error: 0.2429\n",
            "Epoch 996/1000, Mean Squared Error: 0.2429\n",
            "Epoch 997/1000, Mean Squared Error: 0.2429\n",
            "Epoch 998/1000, Mean Squared Error: 0.2429\n",
            "Epoch 999/1000, Mean Squared Error: 0.2429\n",
            "Epoch 1000/1000, Mean Squared Error: 0.2429\n",
            "Predictions after training:\n",
            "Input: [0 0], Predicted Output: 0.5122\n",
            "Input: [0 1], Predicted Output: 0.5049\n",
            "Input: [1 0], Predicted Output: 0.5047\n",
            "Input: [1 1], Predicted Output: 0.4677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Milestone 3: Convolutional Neural Networks (CNNs) (1980s-1990s)\n"
      ],
      "metadata": {
        "id": "IrZ5hh1G0jLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Networks (CNNs) are a specialized type of neural network architecture that is particularly well-suited for processing grid-like data, such as images. CNNs use a combination of convolutional layers, pooling layers, and fully connected layers to learn hierarchical representations of visual data.\n",
        "\n"
      ],
      "metadata": {
        "id": "e9q6BL_b0kft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the CNN architecture\n",
        "model = models.Sequential([\n",
        "    # First convolutional layer\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second convolutional layer\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third convolutional layer\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Flatten the output to feed into a densely connected layer\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Fully connected layers\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)  # Output layer with 10 units (corresponding to 10 classes)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN\n",
        "history = model.fit(train_images, train_labels, epochs=3,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the trained model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Plot training history (optional)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "ORc5_FLp0pTF",
        "outputId": "2dd35309-eb84-469a-e885-c77ab0be7bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 70s 44ms/step - loss: 1.5827 - accuracy: 0.4201 - val_loss: 1.3501 - val_accuracy: 0.5222\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 65s 42ms/step - loss: 1.2176 - accuracy: 0.5691 - val_loss: 1.1548 - val_accuracy: 0.5894\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.0698 - accuracy: 0.6237 - val_loss: 1.0530 - val_accuracy: 0.6210\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 1.0530 - accuracy: 0.6210\n",
            "Test accuracy: 0.6209999918937683\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 4: Deep Learning Frameworks (2000s-present)\n"
      ],
      "metadata": {
        "id": "M32jLgSF09Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch is an open-source deep learning framework developed by Facebook's AI Research lab (FAIR). It provides a flexible platform for building and training neural networks with support for automatic differentiation, dynamic computation graphs, and GPU acceleration. PyTorch has gained popularity due to its intuitive syntax and Pythonic interface, making it a preferred choice for both researchers and practitioners in the deep learning community."
      ],
      "metadata": {
        "id": "3nZ8L2es0_NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define a fully connected neural network\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)  # Flatten the input images\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the neural network, loss function, and optimizer\n",
        "model = NeuralNetwork()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the neural network\n",
        "def train(model, train_loader, criterion, optimizer, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Evaluate the trained model\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Train and evaluate the model\n",
        "train(model, train_loader, criterion, optimizer, epochs=5)\n",
        "evaluate(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY4Bxa0m0-NF",
        "outputId": "cc79e48a-80be-4367-ce59-44672d773513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 138590323.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 76378117.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 42334502.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14699482.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch 1, Loss: 0.3993372688693469\n",
            "Epoch 2, Loss: 0.18736197790706843\n",
            "Epoch 3, Loss: 0.13723674110933218\n",
            "Epoch 4, Loss: 0.11126982669201074\n",
            "Epoch 5, Loss: 0.09448662408188716\n",
            "Test Accuracy: 96.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 5: Transformers and Attention Mechanism (2017-present)\n"
      ],
      "metadata": {
        "id": "6fy7eMV51Fg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers are a type of neural network architecture introduced in the paper \"Attention is All You Need\" by Vaswani et al. in 2017. They rely on self-attention mechanisms to weigh the importance of different input tokens dynamically, enabling efficient processing of sequences without relying on recurrence or convolution. Attention mechanisms allow Transformers to focus on relevant parts of the input sequence when making predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "BerL75L81Htd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "# Define the Transformer model components\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        assert d_model % self.num_heads == 0\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.query_dense = Dense(d_model)\n",
        "        self.key_dense = Dense(d_model)\n",
        "        self.value_dense = Dense(d_model)\n",
        "\n",
        "        self.dense = Dense(d_model)\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(inputs, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        scaled_attention_logits = tf.matmul(query, key, transpose_b=True)\n",
        "        scaled_attention_logits /= tf.math.sqrt(tf.cast(self.depth, tf.float32))\n",
        "\n",
        "        if mask is not None:\n",
        "            scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "\n",
        "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
        "        output = tf.reshape(output, (batch_size, -1, self.d_model))\n",
        "\n",
        "        output = self.dense(output)\n",
        "        return output\n",
        "\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [Dense(ff_dim, activation=\"relu\"), Dense(d_model),]\n",
        "        )\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs[\"query\"] + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Create a Transformer model using the Keras functional API\n",
        "\n",
        "def create_transformer_model(input_shape, num_layers, d_model, num_heads, ff_dim, num_classes, dropout_rate=0.1):\n",
        "    inputs = Input(shape=input_shape, name=\"input_layer\")\n",
        "    x = inputs\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x = TransformerBlock(d_model, num_heads, ff_dim, dropout_rate)(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"transformer_model\")\n",
        "    return model\n",
        "\n",
        "# Prepare the data and train the Transformer model\n",
        "\n",
        "# Assume we have prepared data X_train, y_train, X_test, y_test\n",
        "# input_shape = (sequence_length, embedding_dim)\n",
        "\n",
        "input_shape = (100, 128)  # Example input shape (sequence_length, embedding_dim)\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_classes = 10\n",
        "dropout_rate = 0.1\n",
        "\n",
        "model = create_transformer_model(input_shape, num_layers, d_model, num_heads, ff_dim, num_classes, dropout_rate)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Assuming X_train, y_train, X_test, y_test are your training and test data\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "BDFjd4uY1GU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}